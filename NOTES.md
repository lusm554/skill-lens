# Заметки процесса разработки

## Организация и обработка данных

[2025 Dec 2 18:14] Способ огранизации данных S3 Data Lake - Medallion Architecture. Bronze - ingestion слой, забираем сырые данные из hh.ru api как есть. Silver - очистка, дедупликация, структурирование, форматирование данных. Gold - агрегированные, чистые, оптимизированные данные под бизнес (приложения, отчетность, аналитика, дешы, ml модели и тд). Данные в формате parquet с партиционированием по дате.


[2025 Dec 2 18:42] Реализация Medallion Architecture в Data Lakehouse (гибрид Data Lake и Data Warehouse). Слои Bronze/Silver/Gold + по необходимости слой Serving - реплицированные данные из Gold в СУБД под специфику потребителя данных (например под web/phone приложение подходит СУБД Postgres).


[2025 Dec 2 18:55] Потоки на Airflow. Итоговый выбор Medallion Architecture в Data Lake, тк Data LakeHouse поверх S3 добавляет Delta Lake/Apache Iceberg/Apache Hudi для свойств БД. Для небольшого приложения LakeHouse перебор, хоть и интересно.


[2025 Dec 2 19:02] Посоветовались с Gemini:

**Схема пайплайна:**

1.  **Bronze (Loader DAG):**
    *   **Tool:** Python (`aiohttp`).
    *   **Action:** API -> S3 (`.jsonl.gz`).
    *   *Здесь не нужны ни Polars, ни DuckDB, просто потоковая запись в файл.*

2.  **Silver (Processor DAG):**
    *   **Tool: Polars.**
    *   **Почему:** Polars великолепен в обработке вложенных структур (nested JSON). У него очень удобный API для `struct` и `list` колонок, чтобы "расплющить" (unnest) сложные ответы HH.ru в плоскую таблицу. DuckDB с JSON работает чуть более многословно.
    *   **Action:** Читает JSONL Bronze -> Чистит, нормализует, Дедуплицирует (в рамках батча) -> Пишет Parquet Silver (партиционированный по дате публикации вакансии, а не дате скачивания!).

3.  **Gold (Analytical DAG / Views):**
    *   **Tool: DuckDB.**
    *   **Почему:** Gold слой — это агрегаты, джойны и SQL-логика (например, "Топ-10 навыков для Python разработчиков"). DuckDB — это SQL-движок. Писать аналитические витрины на SQL (через dbt или просто SQL в DuckDB) часто понятнее, чем на DataFrame API. Плюс, DuckDB умеет читать Parquet файлы Silver слоя как одну виртуальную таблицу без копирования данных.
    *   **Action:** SQL-запросы поверх Silver Parquet -> Сохранение небольших Parquet/CSV файлов для отчетов или бэкенда.


[2025 Dec 3 21:51] Реализован Loader ETL поток. Слабые места: 1) Дробления по времени не достаточно для пиковых периодов, например, когда за 30 секу публикуется больше 2тыс вакансий. 2) Поток грузит все данные сначала в RAM, затем в дисковое пространство контейнера, только потом в S3, это узкое горлышко, при пиковых нагрузках поток упадет, да и ресурсы можно потреблять разумнее при потоковой/batch'евой загрузке в s3. Также надо расширить лимит hardware для airflow-worker контейнера чтобы высвободить весь потенциал асинхронного скрипта выгрузки hhru.

[2025 Dec 3 22:33] Доавлена батч обработка вакансий - выгружаем в RAM N-ое кол-во вакансий, сжимаем gzip и сохраняем в s3. Механизм пропуска уже скачанных интервалов не реализован, тк 1) система динамическая, hhru api может вернуть другие результаты на один запрос 2) State recovery требует системы состояний, которая усложнит код в разы, а профита сильного не даст ИМХО.

[2025 Dec 10 10:30] Для silver слоя лучше использовать OBT (One Big Table) c частичным flate'ом часто используемых полей. Это лучше подходит для Data Lake + parquet.

[2025 Dec 10 14:10] Переписал silver dag с Polars на DuckDB. Polars работает отлично, но метод дедупликации lazy_df.unique собирает хеш таблицу в RAM, без возможности offload'a на диск. RAM не хватает. Зато DuckDB имеет возможность offload'a на диск и гибкие настройки потребления RAM. На DuckDB silver DAG выполняется 7 секунд для 300тыс jsonl строк с nested структурой. Это имба.

[2025 Dec 11 08:00] ETL потоки bronze и silver слоев готовы. На ежедневной основе собираются все доступные вакансии hh.ru T-1 и сохраняются в parquet zstd с партиционированием year-month-day. Нюансы/доработки: 1) Сейчас партиционирование по logical date airflow, нужно перевести на UTC hh.ru publish_date, тк hh.ru api бывает возвращает вакансии вне рамках запрашиваемой даты 2) Потоки запускаются независимо друг от друга, они как бы "не знают", что один зависит от другого, нужно добавить зависимость между потоками на уровне airflow 3) Расширить Data Quality Check на silver слое с проверкой появилась/пропала колонка, data drift, data null rate.

[2025 Dec 11 14:00] Добавил тригер чтобы silver запускался от bronze с такой же logical date. Тригер работает через TriggerDagRunOperator. Пробовал Assets, он не предназначен, чтобы передавать logical date между DAG'ами. Также добавил max_active_runs=1() в silver bronze, чтобы не выходить за лимиты RAM, Disk, hh.ru API.

[2025 Deec 17 06:30] Реализованы слои Bronze и Silver. Доступны вакансии hh.ru T-1 в parquet. Бывает, вакансии дублируются по id между днями, тк вакансия с одним id может публиковаться несколько раз. Возможно, это стоит добавить в bronze слой как признак, что вакансия публиковалась N раз.

## DevOps, CI/CD

[2025 Dec 3 13:40] Единый docker compose для airflow и minio, тк далее добавятся http сервер, ml сервис и тд.
